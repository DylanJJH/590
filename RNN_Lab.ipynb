{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Lab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DylanJJH/590/blob/master/RNN_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOkBF0K6P6MC"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tfk\n",
        "import tensorflow.keras.layers as tfkl\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdCU982WwzFo"
      },
      "source": [
        "In this example, we're going to train a [CharRNN](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) on a body of Shakespearian text. Ultimtely, this is an unsuperived learning task. But similar to our previous explorations in unsupervised DL, we will use an unlabeled dataset and create many samples of labeled data that we can use with our familiar supervised loss functions. The result will be a model that has learned the statistical properties of the input text, and can then be considered a \"generative\" model of language because we can use it to generate synthetic passages of Shakespeare.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX7qrncTRKN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d59d21-295c-4817-ba52-14e9ee665a28"
      },
      "source": [
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iek9QSARq1L"
      },
      "source": [
        "file_path = \"/content/gdrive/My Drive/anly590-datasets/shakespeare.txt\"\n",
        "\n",
        "with open(file_path,\"r\") as f:\n",
        "  text = f.read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie2LtLF4Vv6A"
      },
      "source": [
        "We've loaded our Shakespeare text, let's take a look at a random snippet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVFmTUsGWePe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f390d7a-0db9-4820-bf6e-a8fa5e2579ba"
      },
      "source": [
        "print(text[31600:32000])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  And there reigns love and all love's loving parts,\n",
            "  And all those friends which I thought buried.\n",
            "  How many a holy and obsequious tear\n",
            "  Hath dear religious love stol'n from mine eye,\n",
            "  As interest of the dead, which now appear,\n",
            "  But things removed that hidden in thee lie.\n",
            "  Thou art the grave where buried love doth live,\n",
            "  Hung with the trophies of my lovers gone,\n",
            "  Who all their parts of me\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLXQHFUsW0xu"
      },
      "source": [
        "We need to convert our text into numeric arrays, the next several blocks accomplish this.\n",
        "\n",
        "First, we'll create a mapping between characters and their numeric index. We'll also create the reverse mapping, which is useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkvcQEUASXQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10eeac3-d0a0-4726-c7c9-8a04ec3d2b5a"
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XexyPZdAXC0p"
      },
      "source": [
        "Next, we'll create a training set of sub-sequences. Remember, we're trying to train a model to be able to predict the next chracter if it is given several characters of a subsequence. So we will create training pairs where each X is a fixed-length subsequences and each Y is the corresponding next letter in the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej4RdC76S7RB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3920121d-e113-4474-ca4f-c1c57fb2f426"
      },
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sub_sequences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sub_sequences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sub_sequences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 1819633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVHru3qPWX8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b2fbd3-194c-40a3-e7a1-5a12fab6022a"
      },
      "source": [
        "k=300\n",
        "print(\"(Sequence):\\n\" + sub_sequences[k])\n",
        "print(\"\\n(Target Character): \\n\" + next_chars[k])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Sequence):\n",
            "rary*\n",
            "in the presentation of The Complet\n",
            "\n",
            "(Target Character): \n",
            "e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD2QxlOAW8zQ"
      },
      "source": [
        "Next we'll create one-hot vectors for our sub-sequences. The tensor we create here will be shaped as (num_sequences x sequence_length x alphabet_size)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfQRBmiNWehk"
      },
      "source": [
        "X = np.zeros((len(sub_sequences), maxlen, len(chars)), dtype=np.uint8 )\n",
        "Y = np.zeros((len(sub_sequences), len(chars)), dtype=np.uint8)\n",
        "for i, seq in enumerate(sub_sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "        Y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4qxjsGDXLtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f7a7cd8-c2a4-4de5-e2d5-9c2037c14a46"
      },
      "source": [
        "X[0,0,:]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "423pgyKqXnE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ede6748-8411-43a7-b167-88d81d46efa4"
      },
      "source": [
        "Y[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dJrr1caYVnI"
      },
      "source": [
        "Our RNN model will be quite simple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95NSRVMpYGAT"
      },
      "source": [
        "char_rnn = Sequential()\n",
        "char_rnn.add(tfkl.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "char_rnn.add(tfkl.Dense(len(chars),activation=\"softmax\"))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4xdUMP_Y6iu"
      },
      "source": [
        "char_rnn.compile(loss='categorical_crossentropy', optimizer=tfk.optimizers.RMSprop(lr=0.01))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGDTEd0GZFNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94f0f43-4136-4147-a2c7-47a3162c270c"
      },
      "source": [
        "char_rnn.fit(X,Y, epochs=20, batch_size=1024)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1777/1777 [==============================] - 28s 16ms/step - loss: 1.7162\n",
            "Epoch 2/20\n",
            "1777/1777 [==============================] - 28s 16ms/step - loss: 1.4210\n",
            "Epoch 3/20\n",
            "1777/1777 [==============================] - 29s 16ms/step - loss: 1.3736\n",
            "Epoch 4/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.3476\n",
            "Epoch 5/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.3312\n",
            "Epoch 6/20\n",
            "1777/1777 [==============================] - 31s 17ms/step - loss: 1.3193\n",
            "Epoch 7/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.3100\n",
            "Epoch 8/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.3028\n",
            "Epoch 9/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2986\n",
            "Epoch 10/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2927\n",
            "Epoch 11/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2898\n",
            "Epoch 12/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2832\n",
            "Epoch 13/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2807\n",
            "Epoch 14/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2780\n",
            "Epoch 15/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2738\n",
            "Epoch 16/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2723\n",
            "Epoch 17/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2705\n",
            "Epoch 18/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2679\n",
            "Epoch 19/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2659\n",
            "Epoch 20/20\n",
            "1777/1777 [==============================] - 30s 17ms/step - loss: 1.2647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa8d8fdabe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hhAWPgRX96V"
      },
      "source": [
        "Once we have a trained model, we can simulate new text by making predictions about the next character and then drawing characters in proportion to the predicted probabilities. And then simple repeat that process over and over, each time drawing the next character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMpJwYSsZSoc"
      },
      "source": [
        "def draw_char(probs):\n",
        "    probs = np.asarray(probs).astype('float64')\n",
        "    if sum(probs) != 1.0:\n",
        "      probs = probs / np.sum(probs)\n",
        "    draw = np.random.choice(range(len(probs)) , p=probs)\n",
        "    return draw\n",
        "\n",
        "def sample_text(model, sample_length=100):\n",
        "    start = np.random.randint(0, len(text) - maxlen - 1)\n",
        "    sequence = text[start: start + maxlen]\n",
        "  \n",
        "    x_preds = np.zeros((sample_length, maxlen, len(chars)))\n",
        "    for i in range(sample_length):\n",
        "        for t, char in enumerate(sequence[-maxlen:]):\n",
        "            x_preds[i, t, char_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(np.expand_dims(x_preds[i,:,:], axis=0), verbose=0)[0]\n",
        "        next_index = draw_char(preds)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        sequence += next_char\n",
        "    return sequence"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHD5iDlHayL7"
      },
      "source": [
        "sim = sample_text(char_rnn,sample_length=500) "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOP0ljRtOEmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e85fbc-ecb9-414e-9414-b5a665017b97"
      },
      "source": [
        "print(sim)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rrow night, when Phoebe doth behold\n",
            "    These an humous time with any doyinging fell\n",
            "    Hear all the glue of like some obscrab!\n",
            "    and epace in my sword mine! I was there too tremble.\n",
            "  TIMON. Most humor\n",
            "   Then were heart of heavy roils went.\n",
            "  ULYSSES. As in.\n",
            "COE'Sur! Antegar, and by, and forture me nor plainters!\n",
            "  ROSALINE. If Attronion where  \n",
            "    in anything and yust rostacted, if throst\n",
            "    Armish undertop'd in haunting dishmes,\n",
            "    To bear her night to marcy mavi'd, and with him,\n",
            "    In abassing, and long fire me! I am fits\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj4kXg4BTbOc"
      },
      "source": [
        "Notice that we can do pretty well to learn the typical statistical patterns of this text and then simulate new text that appears to be very similar to legitimate Shakespeare. \n",
        "\n",
        "But just a caution - we can also do pretty well with a much simpler method (Markov model): http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139\n",
        "\n",
        "So the lesson is to try something simple before jumping right in to deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5IE5xprp3RS"
      },
      "source": [
        "## Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoN_s6nQsDdn"
      },
      "source": [
        "In this example, we're going to use an RNN for sequence classification. The task we'll set up is to generate a training set of randomized strings, and train our model to detect whether a string contains any vowels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isy5RPDdsTYT"
      },
      "source": [
        "First, we'll create a training dataset of short randomized character sequences and the corresponding label of whether or not they contain at least one vowel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE6C-Xl6p5W7"
      },
      "source": [
        "import string"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI7QA2Ewp-ZJ"
      },
      "source": [
        "def contains_vowels(sequence):\n",
        "  vowels = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n",
        "  return any([vowel in list(sequence) for vowel in vowels])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ9cEhMrqtoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac398a71-5090-4206-ceda-756c85da2f9f"
      },
      "source": [
        "contains_vowels(\"gradient\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwBEUPYwp9Z0"
      },
      "source": [
        "sequences = []\n",
        "labels = []\n",
        "for i in range(10000):\n",
        " char_list = np.random.choice( list(string.ascii_lowercase), size = 5, replace=True)\n",
        " seq = \"\".join(char_list)\n",
        " sequences.append(seq)\n",
        " labels.append(int(contains_vowels(seq)))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkJXdy5krgHn"
      },
      "source": [
        "df = pd.DataFrame({\"sequence\": sequences, \"label\":labels})"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubAQf53Dr8zy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "d2e93c0a-b8f9-4377-aa9e-9c1aec284a52"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nuwbk</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ieaxn</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fnbjv</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ynpis</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tpikw</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sequence  label\n",
              "0    nuwbk      1\n",
              "1    ieaxn      1\n",
              "2    fnbjv      0\n",
              "3    ynpis      1\n",
              "4    tpikw      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xkX8Xa8sfID"
      },
      "source": [
        "Next, set up and train an RNN (of any type) to solve this task. What preprocessing will you need to do first on the raw data in order to prepare it for the network?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M4Sj4XHr9hj"
      },
      "source": [
        "# Data Preprocessing\n",
        "# your code here\n",
        "chr = list(string.ascii_lowercase)\n",
        "chr_idx = dict((c, i) for i, c in enumerate(chr))\n",
        "idx_chr = dict((i, c) for i, c in enumerate(chr))\n",
        "\n",
        "X = np.zeros((len(sequences),5,26), dtype=np.uint8)\n",
        "for i, seq in enumerate(sequences):\n",
        "  for t,char in enumerate(seq):\n",
        "        X[i,t,chr_idx[char]] = 1"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og8gtSgHslED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2007ee5-9d4d-44d3-c864-645283535641"
      },
      "source": [
        "# Model setup and training\n",
        "# your code here\n",
        "RNN = Sequential()\n",
        "RNN.add(tfkl.LSTM(128, input_shape=(5,26)))\n",
        "RNN.add(tfkl.Dense(1,activation=\"sigmoid\"))\n",
        "RNN.compile(loss='binary_crossentropy', optimizer=tfk.optimizers.RMSprop(lr=0.01),metrics=['accuracy'])\n",
        "RNN.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 128)               79360     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 79,489\n",
            "Trainable params: 79,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSLXwJvJszDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb65667-f545-4e09-a226-3f8d182dbdfb"
      },
      "source": [
        "Y = np.array(labels)\n",
        "results = RNN.fit(X,Y,epochs=20,steps_per_epoch=20,batch_size=400)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7751\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9732\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9956\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9964\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9956\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9854\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 3.0933e-04 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 9.6989e-05 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 3.6898e-05 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9920\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 3.1237e-04 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 7.6754e-05 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 2.8180e-05 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1.3331e-05 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 6.2626e-06 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9961\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 3.3068e-04 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 6.0371e-05 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 2.0230e-05 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 7.3788e-06 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT_YDZ_ju2kO"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}